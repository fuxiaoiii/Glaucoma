{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec31a4d8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T16:26:37.840989Z",
     "end_time": "2023-05-01T16:26:37.884986Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc003fc1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T16:26:37.884986Z",
     "end_time": "2023-05-01T16:26:37.989986Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(s):\n",
    "    torch.manual_seed(s)\n",
    "    torch.cuda.manual_seed_all(s)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(s)\n",
    "    random.seed(s)\n",
    "    os.environ['PYTHONHASHSEED'] = str(s)\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0993a76",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T16:26:37.998986Z",
     "end_time": "2023-05-01T16:26:38.128488Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.exposure import equalize_adapthist\n",
    "from skimage.transform import warp_polar\n",
    "\n",
    "class CLAHE(torch.nn.Module):\n",
    "    def forward(self, img):\n",
    "        image = np.array(img, dtype=np.float64) / 255.0\n",
    "        image = equalize_adapthist(image)\n",
    "        image = (image*255).astype('uint8')\n",
    "\n",
    "        return image\n",
    "\n",
    "class POLAR(torch.nn.Module):\n",
    "    def polar(self,image):\n",
    "        return warp_polar(image, radius=(max(image.shape) // 2), multichannel=True)\n",
    "    \n",
    "    def forward(self, image):\n",
    "        image = np.array(image, dtype=np.float64)\n",
    "        image = self.polar(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9f297cf",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T16:26:38.123489Z",
     "end_time": "2023-05-01T16:26:38.249975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311\n",
      "174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangqy/anaconda3/envs/gardnet_envs/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 24, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "split = \"test\"\n",
    "batch_size = 32\n",
    "num_workers = 0\n",
    "train_path = f\"/home/wangqy/gardnet/RIM-ONE_DL_images/partitioned_by_hospital/training_set\" # path to dataset training set\n",
    "path = f\"/home/wangqy/gardnet/RIM-ONE_DL_images/partitioned_by_hospital/{split}_set\"        # path to dataset folder\n",
    "output_dir = \"/home/wangqy/gardnet/RIM-ONE_DL_images/OUTPUTS\"                               # path to save checkpoints\n",
    "\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "            CLAHE(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize(256),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomAffine(0,scale=(1.0,1.3))\n",
    "        ])\n",
    "transform = torchvision.transforms.Compose([\n",
    "            CLAHE(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize(256)\n",
    "        ])\n",
    "train_dataset = ImageFolder(train_path, transform=train_transform)\n",
    "num = int(np.floor(len(train_dataset) * 1))\n",
    "indices = np.random.choice(len(train_dataset), num, replace=False)\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, indices)\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                  batch_size=batch_size, \n",
    "                  shuffle=True,\n",
    "                  num_workers=num_workers,\n",
    "              )\n",
    "test_dataset = ImageFolder(path, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                  batch_size=batch_size, \n",
    "                  shuffle=True,\n",
    "                  num_workers=num_workers,\n",
    "              )\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0725981d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T16:26:38.250976Z",
     "end_time": "2023-05-01T16:27:06.286934Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 1])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_labels = []\n",
    "for j in range(len(train_dataset)):\n",
    "    _labels.append(train_dataset[j][1])\n",
    "_labels = np.asarray(_labels)\n",
    "np.unique(_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18daca84",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T16:27:06.286934Z",
     "end_time": "2023-05-01T16:27:07.038134Z"
    }
   },
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "model_name = \"efficientnet_b0\"\n",
    "pretrained = True\n",
    "dropout = 0.2\n",
    "lr = 0.0005\n",
    "#momentum = 0.1\n",
    "epochs = 20\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "model = timm.create_model(model_name, pretrained=pretrained, num_classes=2, drop_rate=dropout)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "350aaa38",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T16:27:07.039133Z",
     "end_time": "2023-05-01T16:27:07.080132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 0.9490370014311152 from epoch 13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/wangqy/gardnet/Checkpoints/rimonedl_1.pt\"\n",
    "checkpoint = torch.load(path)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "print(\"Best F1 {} from epoch {}\\n\".format(checkpoint[\"best_f1\"], checkpoint[\"epoch\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd683741",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T16:27:07.081132Z",
     "end_time": "2023-05-01T16:31:10.068735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3405173 0.7974359]\n",
      "Resuming training\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/wangqy/anaconda3/envs/gardnet_envs/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 24, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "100%|██████████| 10/10 [00:12<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 0 - loss=0.1157 AUC=0.0386 F1=0.0413  Accuracy=0.0418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/wangqy/anaconda3/envs/gardnet_envs/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 24, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "100%|██████████| 10/10 [00:11<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 1 - loss=0.0524 AUC=0.1756 F1=0.1833  Accuracy=0.1961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/wangqy/anaconda3/envs/gardnet_envs/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 24, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "100%|██████████| 10/10 [00:11<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 2 - loss=0.0258 AUC=0.4359 F1=0.4252  Accuracy=0.4984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/wangqy/anaconda3/envs/gardnet_envs/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 24, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "100%|██████████| 10/10 [00:11<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 3 - loss=0.0177 AUC=0.6633 F1=0.6608  Accuracy=0.6785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/wangqy/anaconda3/envs/gardnet_envs/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 24, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "100%|██████████| 10/10 [00:11<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 4 - loss=0.0133 AUC=0.8347 F1=0.8077  Accuracy=0.8103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/wangqy/anaconda3/envs/gardnet_envs/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 24, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "100%|██████████| 10/10 [00:11<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 5 - loss=0.0114 AUC=0.8690 F1=0.8458  Accuracy=0.8489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/wangqy/anaconda3/envs/gardnet_envs/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 24, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "100%|██████████| 10/10 [00:11<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 6 - loss=0.0096 AUC=0.8758 F1=0.8578  Accuracy=0.8617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/wangqy/anaconda3/envs/gardnet_envs/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 24, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "100%|██████████| 10/10 [00:11<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 7 - loss=0.0080 AUC=0.9145 F1=0.8943  Accuracy=0.8971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/wangqy/anaconda3/envs/gardnet_envs/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 24, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "100%|██████████| 10/10 [00:11<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 8 - loss=0.0066 AUC=0.9272 F1=0.9161  Accuracy=0.9196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/wangqy/anaconda3/envs/gardnet_envs/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 24, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "100%|██████████| 10/10 [00:11<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 9 - loss=0.0057 AUC=0.9288 F1=0.9221  Accuracy=0.9260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/wangqy/anaconda3/envs/gardnet_envs/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 24, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "100%|██████████| 10/10 [00:11<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 10 - loss=0.0052 AUC=0.9495 F1=0.9364  Accuracy=0.9389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/wangqy/anaconda3/envs/gardnet_envs/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 24, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "100%|██████████| 10/10 [00:11<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 11 - loss=0.0042 AUC=0.9580 F1=0.9493  Accuracy=0.9518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/wangqy/anaconda3/envs/gardnet_envs/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 24, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "100%|██████████| 10/10 [00:11<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 12 - loss=0.0052 AUC=0.9494 F1=0.9424  Accuracy=0.9453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/wangqy/anaconda3/envs/gardnet_envs/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 24, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "100%|██████████| 10/10 [00:11<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 13 - loss=0.0044 AUC=0.9554 F1=0.9522  Accuracy=0.9550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/wangqy/anaconda3/envs/gardnet_envs/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 24, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "100%|██████████| 10/10 [00:11<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 14 - loss=0.0040 AUC=0.9640 F1=0.9592  Accuracy=0.9614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/wangqy/anaconda3/envs/gardnet_envs/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 24, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "100%|██████████| 10/10 [00:11<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 15 - loss=0.0040 AUC=0.9580 F1=0.9493  Accuracy=0.9518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/wangqy/anaconda3/envs/gardnet_envs/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 24, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "100%|██████████| 10/10 [00:11<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 16 - loss=0.0035 AUC=0.9683 F1=0.9626  Accuracy=0.9646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/wangqy/anaconda3/envs/gardnet_envs/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 24, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "100%|██████████| 10/10 [00:11<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 17 - loss=0.0036 AUC=0.9699 F1=0.9691  Accuracy=0.9711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/wangqy/anaconda3/envs/gardnet_envs/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 24, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "100%|██████████| 10/10 [00:11<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 18 - loss=0.0033 AUC=0.9726 F1=0.9661  Accuracy=0.9678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/wangqy/anaconda3/envs/gardnet_envs/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 24, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "100%|██████████| 10/10 [00:11<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 19 - loss=0.0033 AUC=0.9667 F1=0.9562  Accuracy=0.9582\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.utils import class_weight\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "weight_referable = class_weight.compute_class_weight(class_weight='balanced', classes = np.unique(_labels), y=_labels).astype('float32')    \n",
    "weight_referable = np.array([weight_referable[0], weight_referable[1]])\n",
    "criterion = CrossEntropyLoss(weight=torch.from_numpy(weight_referable).to(device))\n",
    "print(weight_referable)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "epoch_resume = 0\n",
    "best_f1 = 0.0\n",
    "\n",
    "\n",
    "# Train\n",
    "if epoch_resume < epochs:\n",
    "    print(\"Resuming training\\n\")\n",
    "    for epoch in range(epoch_resume, epochs):\n",
    "        for split in ['Train']:\n",
    "            if split == \"Train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            epoch_total_loss = 0\n",
    "            labels = []\n",
    "            predictions = []\n",
    "            loader = train_loader if split == \"Train\" else val_loader\n",
    "            for batch_num, (inp, target) in enumerate(tqdm(loader)):\n",
    "                labels+=(target)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(inp.to(device))\n",
    "                _, batch_prediction = torch.max(output, dim=1)\n",
    "                predictions += batch_prediction.detach().tolist()\n",
    "                batch_loss = criterion(output, (target).to(device))\n",
    "                epoch_total_loss += batch_loss.item()\n",
    "\n",
    "                if split == \"Train\":\n",
    "                    batch_loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            avrg_loss = epoch_total_loss / loader.dataset.__len__()\n",
    "            accuracy = metrics.accuracy_score(labels, predictions)\n",
    "            confusion = metrics.confusion_matrix(labels, predictions)\n",
    "            _f1_score = f1_score(labels, predictions, average=\"macro\")\n",
    "            auc = sklearn.metrics.roc_auc_score(labels, predictions)\n",
    "            print(\"%s Epoch %d - loss=%0.4f AUC=%0.4f F1=%0.4f  Accuracy=%0.4f\" % (split, epoch, avrg_loss, auc, _f1_score, accuracy))\n",
    "\n",
    "\n",
    "        # save model\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'best_f1': best_f1,\n",
    "            'f1': _f1_score,\n",
    "            'auc': auc,\n",
    "            'loss': avrg_loss,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'opt_dict': optimizer.state_dict(),\n",
    "            #'scheduler_dict': scheduler.state_dict()\n",
    "        }\n",
    "\n",
    "        torch.save(checkpoint, os.path.join(output_dir, f\"checkpoint_{epoch}.pt\"))\n",
    "        if _f1_score > best_f1:\n",
    "            best_f1 = _f1_score\n",
    "            checkpoint[\"best_f1\"] = best_f1\n",
    "            torch.save(checkpoint, os.path.join(output_dir, \"best.pt\"))\n",
    "else:\n",
    "    print(\"Skipping training\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d143e34",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T16:31:10.074735Z",
     "end_time": "2023-05-01T16:31:10.130305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 0.9691185718856538 from epoch 17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = f\"{output_dir}/best.pt\"\n",
    "checkpoint = torch.load(path)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "print(\"Best F1 {} from epoch {}\\n\".format(checkpoint[\"best_f1\"], checkpoint[\"epoch\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30e62fe9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T16:31:10.132293Z",
     "end_time": "2023-05-01T16:31:14.411517Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]/home/wangqy/anaconda3/envs/gardnet_envs/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 24, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.83908\n",
      "[[47  9]\n",
      " [19 99]]\n",
      "Test F1 = 0.82330\n",
      "Test AUC = 0.83913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "model.eval()\n",
    "labels = []\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for (inp, target) in tqdm(test_loader):\n",
    "        labels+=(target)\n",
    "        batch_prediction = model(inp.to(device))\n",
    "        _, batch_prediction = torch.max(batch_prediction, dim=1)\n",
    "        predictions += batch_prediction.detach().tolist()\n",
    "accuracy = metrics.accuracy_score(labels, predictions)\n",
    "print(\"Test Accuracy = %0.5f\" % (accuracy))\n",
    "\n",
    "confusion = metrics.confusion_matrix(labels, predictions)\n",
    "print(confusion)\n",
    "\n",
    "_f1_score = f1_score(labels, predictions, average=\"macro\")\n",
    "print(\"Test F1 = %0.5f\" % (_f1_score))\n",
    "\n",
    "auc = sklearn.metrics.roc_auc_score(labels, predictions)\n",
    "print(\"Test AUC = %0.5f\" % (auc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
